{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDmDy6Iax_Cc"
   },
   "source": [
    "We are going to use these two sentences and check how model understand the context. Both sentences are same but written in different way so we can check the models that how they treat. We have used the base models and our own fine tuned model to check the similarity which will tell us that how model understand the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "kI8mEeJxx_Ce"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "jkQEIyHtx_Cf"
   },
   "outputs": [],
   "source": [
    "text1 = \"الشخص الذي يجلب الابتسامة التي تلمس قلبك\"\n",
    "text2 = \"عن الشخص اللي يخلي الإبتسامة توصل لين قلبك\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7P5lvziuEDQ5",
    "outputId": "459e71e7-9590-41d0-cb1c-c54ab33c6ab6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the two sentences: 0.8692\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv02\")\n",
    "model = AutoModel.from_pretrained(\"aubmindlab/bert-base-arabertv02\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "inputs = tokenizer([text1, text2], padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "cls_embeddings = cls_embeddings.cpu().numpy()\n",
    "\n",
    "similarity = cosine_similarity([cls_embeddings[0]], [cls_embeddings[1]])\n",
    "\n",
    "print(f\"Similarity between the two sentences: {similarity[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5m5yd40EDQ6",
    "outputId": "e2eb5cfa-5c0d-4d72-88dd-53622a42cfcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the two sentences: 0.9330\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nisarahmedrana/arabert_finetuned_model\")\n",
    "model = AutoModel.from_pretrained(\"nisarahmedrana/arabert_finetuned_model\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "inputs = tokenizer([text1, text2], padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "cls_embeddings = cls_embeddings.cpu().numpy()\n",
    "\n",
    "similarity = cosine_similarity([cls_embeddings[0]], [cls_embeddings[1]])\n",
    "\n",
    "print(f\"Similarity between the two sentences: {similarity[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEpfiMDH4ydd",
    "outputId": "f4e0adab-da90-484f-f6f5-049d0ef54ef6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the two sentences: 0.8323\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-large-arabic\")\n",
    "model = AutoModel.from_pretrained(\"asafaya/bert-large-arabic\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "inputs = tokenizer([text1, text2], padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "cls_embeddings = cls_embeddings.cpu().numpy()\n",
    "\n",
    "similarity = cosine_similarity([cls_embeddings[0]], [cls_embeddings[1]])\n",
    "\n",
    "print(f\"Similarity between the two sentences: {similarity[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccVT1fxj4yg_",
    "outputId": "99b9bd7c-4ac3-413d-a6dc-4b7f4424e11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the two sentences: 0.8946\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nisarahmedrana/arabic_finetuned_model\")\n",
    "model = AutoModel.from_pretrained(\"nisarahmedrana/arabic_finetuned_model\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "inputs = tokenizer([text1, text2], padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "cls_embeddings = cls_embeddings.cpu().numpy()\n",
    "\n",
    "similarity = cosine_similarity([cls_embeddings[0]], [cls_embeddings[1]])\n",
    "\n",
    "print(f\"Similarity between the two sentences: {similarity[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwLje57ix_Ch"
   },
   "source": [
    "We can see that the fine tuned models are understand the context better and that is the reason, there is more similarity on the fine tuned models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvO6xT-Dx_Ch"
   },
   "source": [
    "We have fine-tuned models in order to adopt and to handle multi-label classification tasks where text overlap for different classes."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
